{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Understanding Self-Attention in Simple Terms**  \n",
    "\n",
    "Self-Attention is a mechanism that allows a model to **focus on different parts of the input sentence when processing each token**. It helps capture relationships between words, even if they are far apart in a sentence.  \n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tfauBl5knVDQqSoobIwlqw.png)\n",
    "\n",
    "---\n",
    "\n",
    "## **üìå 1. What Do Q, K, V Represent?**  \n",
    "\n",
    "### **1Ô∏è‚É£ Query (Q) ‚Üí \"What should I focus on?\"**  \n",
    "- **Each token asks: \"Who is important to me?\"**\n",
    "- It's a transformed version of the input token, used to determine **how much attention to pay to other tokens**.\n",
    "\n",
    "### **2Ô∏è‚É£ Key (K) ‚Üí \"What am I?\"**  \n",
    "- **Each token declares: \"This is what I represent.\"**\n",
    "- It helps measure **how relevant a token is** to another token‚Äôs Query.\n",
    "\n",
    "### **3Ô∏è‚É£ Value (V) ‚Üí \"What information do I carry?\"**  \n",
    "- **Each token provides information that might be useful to others.**\n",
    "- It holds the actual content that will be passed on after computing attention.\n",
    "\n",
    "---\n",
    "\n",
    "## **üìå 2. How Does Self-Attention Work?**\n",
    "Let's say we have the sentence:  \n",
    "**\"The quick brown fox jumps\"**  \n",
    "\n",
    "Each word is represented as a vector (embedding), and we compute Q, K, and V for each token.\n",
    "\n",
    "| Token  | Query (Q) | Key (K) | Value (V) |\n",
    "|--------|----------|---------|---------|\n",
    "| \"The\"  | \"Who should I attend to?\" | \"I represent 'The'\" | \"My info is 'The'\" |\n",
    "| \"quick\"  | \"Who should I attend to?\" | \"I represent 'quick'\" | \"My info is 'quick'\" |\n",
    "| \"brown\"  | \"Who should I attend to?\" | \"I represent 'brown'\" | \"My info is 'brown'\" |\n",
    "| \"fox\"  | \"Who should I attend to?\" | \"I represent 'fox'\" | \"My info is 'fox'\" |\n",
    "\n",
    "---\n",
    "\n",
    "## **üìå 3. How Is Attention Computed?**\n",
    "### **1Ô∏è‚É£ Compute Scores (How similar is Q to K?)**\n",
    "We take the **dot product of Query and Key** to compute a **score** for each word pair:\n",
    "\n",
    "$$\n",
    "\\text{Score} = \\frac{QK^T}{\\sqrt{d_k}}\n",
    "$$\n",
    "\n",
    "- If **Q and K are similar**, the score is **high** (meaning the token is important).\n",
    "- If **Q and K are different**, the score is **low** (meaning the token is less important).\n",
    "\n",
    "üîπ **Example Scores (before softmax):**  \n",
    "| Q (query) | K (key) for \"quick\" | K (key) for \"brown\" | K (key) for \"fox\" |\n",
    "|-----------|----------------|----------------|--------------|\n",
    "| \"quick\"   | **1.0**  (self-related) | **0.8** (related) | **0.2** (not related) |\n",
    "\n",
    "#### Why divided by $\\sqrt{d_k}$\n",
    "\n",
    "| Aspect            | Meaning of $\\sqrt{d_k}$   |\n",
    "|-------------------|---------------------------|\n",
    "| **Numerical Stability**  | Ensures that the attention scores remain in a manageable range, avoiding extreme values. |\n",
    "| **Geometric**         | Normalizes the dot product to focus on true similarity (alignment) between vectors, not their magnitudes. |\n",
    "| **Statistical**      | Prevents the dot product from growing too large as the dimension increases, ensuring that softmax behaves predictably. |\n",
    "\n",
    "##### **In short**, the $\\sqrt{d_k}$ term acts as a **scaling factor** to:\n",
    "1. Prevent the dot product from becoming too large.\n",
    "2. Normalize the attention scores to reflect true similarity.\n",
    "3. Ensure that the softmax function behaves in a stable, predictable way across different vector dimensions.\n",
    "\n",
    "> The **softmax** function is sensitive to the scale of its inputs. If the input scores to softmax are too large (which could happen without ($\\sqrt{d_k}$), the output probabilities would become too extreme (close to 0 or 1), making it difficult for the model to differentiate between tokens. The ($\\sqrt{d_k}$) scaling keeps the scores within a range where softmax can **distribute attention more evenly**, preventing extreme focusing on just one token.\n",
    "\n",
    "---\n",
    "\n",
    "### **2Ô∏è‚É£ Apply Softmax (Normalize Scores to Probabilities)**\n",
    "Softmax ensures that all attention scores sum to **1**, making them interpretable as probabilities:\n",
    "\n",
    "$$\n",
    "\\text{Attention Weights} = \\text{softmax}(\\text{Score})\n",
    "$$\n",
    "\n",
    "üîπ **Example (after softmax normalization):**  \n",
    "| Token | Weight (for \"quick\") |\n",
    "|-------|--------------------|\n",
    "| quick | **0.50** (strong focus) |\n",
    "| brown | **0.40** (some focus) |\n",
    "| fox   | **0.10** (less focus) |\n",
    "\n",
    "---\n",
    "\n",
    "### **3Ô∏è‚É£ Compute the Final Output**\n",
    "The **final attention output** is a weighted sum of all Value (V) vectors:\n",
    "$$\n",
    "\\text{Output} = \\sum (\\text{Attention Weights} \\times V)\n",
    "$$\n",
    "\n",
    "- If **\"quick\" attends more to \"brown\"**, its final representation will **contain more information from \"brown\"**.\n",
    "- If **\"fox\" attends mostly to itself**, it won‚Äôt change much.\n",
    "\n",
    "---\n",
    "\n",
    "## **üìå 4. Example with Code**\n",
    "Here‚Äôs an example using NumPy:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Simulated word embeddings (4 tokens, 3 dimensions each)\n",
    "X = np.array([\n",
    "    [0.1, 0.3, 0.5],  # The\n",
    "    [0.2, 0.4, 0.6],  # quick\n",
    "    [0.3, 0.5, 0.7],  # brown\n",
    "    [0.4, 0.6, 0.8]   # fox\n",
    "])\n",
    "\n",
    "# Random weight matrices\n",
    "W_Q, W_K, W_V = np.random.rand(3, 3), np.random.rand(3, 3), np.random.rand(3, 3)\n",
    "\n",
    "# Compute Q, K, V\n",
    "Q, K, V = X @ W_Q, X @ W_K, X @ W_V\n",
    "\n",
    "# Compute Scores (Q @ K.T)\n",
    "scores = Q @ K.T / np.sqrt(3)\n",
    "\n",
    "# Apply Softmax\n",
    "attention_weights = np.exp(scores) / np.sum(np.exp(scores), axis=-1, keepdims=True)\n",
    "\n",
    "# Compute Final Output\n",
    "output = attention_weights @ V\n",
    "\n",
    "print(\"\\nAttention Weights:\\n\", attention_weights)\n",
    "print(\"\\nSelf-Attention Output:\\n\", output)\n",
    "```\n",
    "\n",
    "üîπ **Example Output (Attention Weights):**\n",
    "```\n",
    "Attention Weights:\n",
    "[[0.40  0.35  0.15  0.10]\n",
    " [0.30  0.40  0.20  0.10]\n",
    " [0.20  0.35  0.30  0.15]\n",
    " [0.10  0.25  0.30  0.35]]\n",
    "```\n",
    "- \"quick\" **attends more to \"brown\" (0.35)** than to \"fox\" (0.10).\n",
    "- \"fox\" focuses **mostly on itself and brown**.\n",
    "\n",
    "üîπ **Final Output (New Representation):**\n",
    "```\n",
    "Self-Attention Output:\n",
    "[\n",
    "  [0.31, 0.45, 0.59],\n",
    "  [0.32, 0.46, 0.60],\n",
    "  [0.33, 0.48, 0.61],\n",
    "  [0.35, 0.50, 0.63]\n",
    "]\n",
    "```\n",
    "- \"quick\" now **contains information from \"brown\"**.\n",
    "- \"fox\" learned a bit about \"brown\", but still mostly represents itself.\n",
    "\n",
    "---\n",
    "\n",
    "## **üìå 5. Summary**\n",
    "| **Component** | **Meaning** |\n",
    "|-------------|------------|\n",
    "| **Q (Query)** | \"What information should I focus on?\" |\n",
    "| **K (Key)** | \"What does this token represent?\" |\n",
    "| **V (Value)** | \"What information does this token contain?\" |\n",
    "| **Score** | Similarity between Q and K (how relevant is a token?) |\n",
    "| **Attention Weights** | Softmax-normalized scores (focus level on each token) |\n",
    "| **Output** | The new representation of each token after considering others |\n",
    "\n",
    "‚úÖ **Self-Attention helps words attend to other words and improve their representation.**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
